{"cells":[{"cell_type":"markdown","metadata":{},"source":["![](https://apps.tsn.go.tz/public/uploads/fd2b657ba7ea5c49c5473dc452481cb0.png)"]},{"cell_type":"markdown","metadata":{},"source":["<h2>   \n","      <font color = blue >\n","            <span style='font-family:Georgia'>\n","            Table of Contents:\n","            </span>   \n","        </font>    \n","</h2>\n","<span style='font-family:Georgia'>\n","    <ol>\n","        <li><a href='#intro'>Introduction</a></li>\n","        <li><a href='#libraries'>Getting Jupyter Ready</a></li>\n","        <li><a href='#import'>Reading & Understanding the data</a></li>\n","        <ol>\n","            <li><a href='#input'>Importing the input files</a></li>\n","            <li><a href='#inspect'>Inspect Data Frames</a></li>\n","        </ol>\n","        <li><a href='#clean'>Data Cleaning & Manipulation</a></li>\n","        <ol>\n","            <li><a href='#null'>Null Value Calculation</a></li>\n","            <li><a href='#clean1'>Analyze & Delete Unnecessary Columns in applicationDF</a></li>\n","            <li><a href='#clean2'>Analyze & Delete Unnecessary Columns in previousDF</a></li>\n","            <li><a href='#stdval'>Standardize Values</a></li>\n","            <li><a href='#dconv'>Data Type Conversion</a></li>\n","            <li><a href='#impute'>Null Value Data Imputation</a></li>\n","            <li><a href='#outlier'>Identifying the outliers</a></li>\n","        </ol>\n","        <li><a href='#analysis'>Data Analysis</a></li>\n","        <ol>\n","            <li><a href='#imbalance'>Imbalance Analysis</a></li>\n","            <li><a href='#pltfunc'>Plotting Functions</a></li>\n","            <li><a href='#catvar'>Categorical Variables Analysis</a></li>\n","            <li><a href='#numvar'>Numeric Variables Analysis</a></li>\n","        </ol>\n","        <li><a href='#merge'>Merged Dataframes Analysis</a></li>\n","        <li><a href='#conclusion'>Conclusions</a></li>\n","    </ol>\n","</span>\n","    "]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"intro\"></a>\n","<h2>   \n","      <font color = blue >\n","            <span style='font-family:Georgia'>\n","            1. Introduction:\n","            </span>   \n","        </font>    \n","</h2>"]},{"cell_type":"markdown","metadata":{},"source":["<h3 >   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            Introduction:\n","            </span>   \n","        </font>    \n","</h3>\n","<p>\n","    <span style='font-family:Georgia'>\n","    This case study aims to give an idea of applying EDA in a real business scenario. In this case study, we will develop a basic understanding of risk analytics in banking and financial services and understand how data is used to minimise the risk of losing money while lending to customers.\n","    </span>\n","</p>   \n","<hr>\n","<h3>\n","    <font color = purple >\n","        <span style='font-family:Georgia'>\n","            Business Understanding:\n","            </span>   \n","        </font>    \n","</h3>\n","<p>\n","    <span style='font-family:Georgia'>\n","    The loan providing companies find it hard to give loans to the people due to their insufficient or non-existent credit history. Because of that, some consumers use it as their advantage by becoming a defaulter. Suppose you work for a consumer finance company which specialises in lending various types of loans to urban customers. You have to use EDA to analyse the patterns present in the data. This will ensure that the applicants capable of repaying the loan are not rejected.<br>\n","        When the company receives a loan application, the company has to decide for loan approval based on the applicant’s profile. Two types of risks are associated with the bank’s decision:\n","    </span>\n","</p>\n","<ul>\n","    <span style='font-family:Georgia'>\n","        <li>If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company</li>\n","        <li>If the applicant is not likely to repay the loan, i.e. he/she is likely to default, then approving the loan may lead to a financial loss for the company.</li>\n","    </span>\n","</ul>\n","    \n","<p><span style='font-family:Georgia'>The data given below contains the information about the loan application at the time of applying for the loan. It contains two types of scenarios:</span></p>\n","<ul>\n","    <span style='font-family:Georgia'> \n","        <li><b>The client with payment difficulties:</b> he/she had late payment more than X days on at least one of the first Y instalments of the loan in our sample</li>\n","        <li><b>All other cases:</b> All other cases when the payment is paid on time</li>\n","    </span>\n","</ul>\n","    \n","<p><span style='font-family:Georgia'>When a client applies for a loan, there are four types of decisions that could be taken by the client/company):</span></p>\n","\n","<ol>\n","    <span style='font-family:Georgia'>\n","        <li><b>Approved:</b> The Company has approved loan Application</li>\n","        <li><b>Cancelled:</b> The client cancelled the application sometime during approval. Either the client changed her/his mind about the loan or in some cases due to a higher risk of the client he received worse pricing which he did not want.</li>\n","        <li><b>Refused:</b> The company had rejected the loan (because the client does not meet their requirements etc.)</li>\n","        <li><b>Unused offer:</b>  Loan has been cancelled by the client but on different stages of the process.</li>\n","    </span>\n","</ol>\n","<hr>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            Business Objective:\n","            </span>   \n","        </font>    \n","</h3>\n","<p>\n","    <span style='font-family:Georgia'>\n","        This case study aims to identify patterns which indicate if a client has difficulty paying their installments which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc. This will ensure that the consumers capable of repaying the loan are not rejected. Identification of such applicants using EDA is the aim of this case study.<br>\n","        In other words, the company wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default.  The company can utilise this knowledge for its portfolio and risk assessment.\n","    </span>\n","</p>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"libraries\"></a>\n","<h2>   \n","      <font color = blue >\n","            <span style='font-family:Georgia'>\n","            2. Getting Jupyter Ready:\n","            </span>   \n","        </font>    \n","</h2>"]},{"cell_type":"markdown","metadata":{},"source":["<h3 name='libraries'>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            2.1 Import Python Libraries:\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.style as style\n","import seaborn as sns\n","import itertools\n","%matplotlib inline\n","\n","# setting up plot style \n","style.use('seaborn-poster')\n","style.use('fivethirtyeight')"]},{"cell_type":"markdown","metadata":{},"source":["<h3 name='libraries'>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            2.2 Supress Warnings:\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["<h3 name='libraries'>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            2.3 Adjust Jupyer Views:\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","pd.set_option('display.expand_frame_repr', False)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"import\"></a>\n","<h2>   \n","      <font color = blue >\n","            <span style='font-family:Georgia'>\n","            3. Reading & Understanding the data\n","            </span>   \n","        </font>    \n","</h2>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"input\"></a>\n","<h3 name='libraries'>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            3.1 Importing the input files\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","# import os\n","# for dirname, _, filenames in os.walk('/kaggle/input'):\n","#     for filename in filenames:\n","#         print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["applicationDF = pd.read_csv(r'./datasets/application_data.csv')\n","previousDF = pd.read_csv(r'./datasets/previous_application.csv')\n","# applicationDF.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF.head()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"inspect\"></a>\n","<h3 name='libraries'>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            3.2 Inspect Data Frames\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Database dimension\n","print(\"Database dimension - applicationDF     :\",applicationDF.shape)\n","print(\"Database dimension - previousDF        :\",previousDF.shape)\n","\n","#Database size\n","print(\"Database size - applicationDF          :\",applicationDF.size)\n","print(\"Database size - previousDF             :\",previousDF.size)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Database column types\n","applicationDF.info(verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF.info(verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking the numeric variables of the dataframes\n","applicationDF.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF.describe()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"clean\"></a>\n","<h2>   \n","      <font color = blue >\n","            <span style='font-family:Georgia'>\n","            4. Data Cleaning & Manipulation\n","            </span>   \n","        </font>    \n","</h2>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"null\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            4.1 Null Value Calculation\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","            4.1.1 applicationDF Missing values\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import missingno as mn\n","mn.matrix(applicationDF)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>Based on the above Matrix, it is evidednt that the dataset has many missing values. Let's check for each column what is the % of missing values\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# % null value in each column\n","round(applicationDF.isnull().sum() / applicationDF.shape[0] * 100.00,2)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>There are many columns in applicationDF dataframe where missing value is more than 40%. Let's plot the columns vs missing value % with 40% being the cut-off marks\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["null_applicationDF = pd.DataFrame((applicationDF.isnull().sum())*100/applicationDF.shape[0]).reset_index()\n","null_applicationDF.columns = ['Column Name', 'Null Values Percentage']\n","fig = plt.figure(figsize=(18,6))\n","ax = sns.pointplot(x=\"Column Name\",y=\"Null Values Percentage\",data=null_applicationDF,color='blue')\n","plt.xticks(rotation =90,fontsize =7)\n","ax.axhline(40, ls='--',color='red')\n","plt.title(\"Percentage of Missing values in application data\")\n","plt.ylabel(\"Null Values PERCENTAGE\")\n","plt.xlabel(\"COLUMNS\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>From the plot we can see the columns in which percentage of null values more than 40% are marked above the red line and the columns which have less than 40 % null values below the red line. Let's check the columns which has more than 40% missing values\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# more than or equal to 40% empty rows columns\n","nullcol_40_application = null_applicationDF[null_applicationDF[\"Null Values Percentage\"]>=40]\n","nullcol_40_application"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# How many columns have more than or euqal to 40% null values ?\n","len(nullcol_40_application)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>Total of 49 columns are there which have more than 40% null values.Seems like most of the columns with high missing values are related to different area sizes on apartment owned/rented by the loan applicant\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","            4.1.2 previousDF Missing Values\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mn.matrix(previousDF)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# checking the null value % of each column in previousDF dataframe\n","round(previousDF.isnull().sum() / previousDF.shape[0] * 100.00,2)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>There are many columns in previousDF dataframe where missing value is more than 40%. Let's plot the columns vs missing value % with 40% being the cut-off marks\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["null_previousDF = pd.DataFrame((previousDF.isnull().sum())*100/previousDF.shape[0]).reset_index()\n","null_previousDF.columns = ['Column Name', 'Null Values Percentage']\n","fig = plt.figure(figsize=(18,6))\n","ax = sns.pointplot(x=\"Column Name\",y=\"Null Values Percentage\",data=null_previousDF,color ='blue')\n","plt.xticks(rotation =90,fontsize =7)\n","ax.axhline(40, ls='--',color='red')\n","plt.title(\"Percentage of Missing values in previousDF data\")\n","plt.ylabel(\"Null Values PERCENTAGE\")\n","plt.xlabel(\"COLUMNS\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>From the plot we can see the columns in which percentage of null values more than 40% are marked above the red line and the columns which have less than 40 % null values below the red line. Let's check the columns which has more than 40% missing values\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# more than or equal to 40% empty rows columns\n","nullcol_40_previous = null_previousDF[null_previousDF[\"Null Values Percentage\"]>=40]\n","nullcol_40_previous"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# How many columns have more than or euqal to 40% null values ?\n","len(nullcol_40_previous)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>Total of 11 columns are there which have more than 40% null values. These columns can be deleted. Before deleting these columns, let's review if there are more columns which can be dropped or not[](http://)\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"clean1\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            4.2 Analyze & Delete Unnecessary Columns in applicationDF\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","            4.2.1 EXT_SOURCE_X\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking correlation of EXT_SOURCE_X columns vs TARGET column\n","Source = applicationDF[[\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\",\"TARGET\"]]\n","source_corr = Source.corr()\n","ax = sns.heatmap(source_corr,\n","            xticklabels=source_corr.columns,\n","            yticklabels=source_corr.columns,\n","            annot = True,\n","            cmap =\"RdYlGn\")"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>Based on the above Heatmap, we can see there is almost no correlation between EXT_SOURCE_X columns and target column, thus we can drop these columns. EXT_SOURCE_1 has 56% null values, where as EXT_SOURCE_3 has close to 20% null values\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# create a list of columns that needs to be dropped including the columns with >40% null values\n","Unwanted_application = nullcol_40_application[\"Column Name\"].tolist()+ ['EXT_SOURCE_2','EXT_SOURCE_3'] \n","# as EXT_SOURCE_1 column is already included in nullcol_40_application \n","len(Unwanted_application)"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","            4.2.2 Flag Document\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking the relevance of Flag_Document and whether it has any relation with loan repayment status\n","col_Doc = [ 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3','FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6','FLAG_DOCUMENT_7', \n","           'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9','FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12','FLAG_DOCUMENT_13',\n","           'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15','FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n","           'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']\n","df_flag = applicationDF[col_Doc+[\"TARGET\"]]\n","\n","length = len(col_Doc)\n","\n","df_flag[\"TARGET\"] = df_flag[\"TARGET\"].replace({1:\"Defaulter\",0:\"Repayer\"})\n","\n","fig = plt.figure(figsize=(21,24))\n","\n","for i,j in itertools.zip_longest(col_Doc,range(length)):\n","    plt.subplot(5,4,j+1)\n","    ax = sns.countplot(df_flag[i],hue=df_flag[\"TARGET\"],palette=[\"r\",\"g\"])\n","    plt.yticks(fontsize=8)\n","    plt.xlabel(\"\")\n","    plt.ylabel(\"\")\n","    plt.title(i)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>The above graph shows that in most of the loan application cases, clients who applied for loans has not submitted FLAG_DOCUMENT_X except FLAG_DOCUMENT_3. Thus, Except for FLAG_DOCUMENT_3, we can delete rest of the columns. Data shows if borrower has submitted FLAG_DOCUMENT_3 then there is a less chance of defaulting the loan.\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Including the flag documents for dropping the Document columns\n","col_Doc.remove('FLAG_DOCUMENT_3') \n","Unwanted_application = Unwanted_application + col_Doc\n","len(Unwanted_application)"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","            4.2.3 Contact Parameters\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# checking is there is any correlation between mobile phone, work phone etc, email, Family members and Region rating\n","contact_col = ['FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE',\n","       'FLAG_PHONE', 'FLAG_EMAIL','TARGET']\n","Contact_corr = applicationDF[contact_col].corr()\n","fig = plt.figure(figsize=(8,8))\n","ax = sns.heatmap(Contact_corr,\n","            xticklabels=Contact_corr.columns,\n","            yticklabels=Contact_corr.columns,\n","            annot = True,\n","            cmap =\"RdYlGn\",\n","            linewidth=1)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>There is no correlation between flags of mobile phone, email etc with loan repayment; thus these columns can be deleted\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# including the 6 FLAG columns to be deleted\n","contact_col.remove('TARGET') \n","Unwanted_application = Unwanted_application + contact_col\n","len(Unwanted_application)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br> \n","        Total 76 columns can be deleted from applicationDF\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Dropping the unnecessary columns from applicationDF\n","applicationDF.drop(labels=Unwanted_application,axis=1,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Inspecting the dataframe after removal of unnecessary columns\n","applicationDF.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# inspecting the column types after removal of unnecessary columns\n","applicationDF.info()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>After deleting unnecessary columns, there are 46 columns remaining in applicationDF\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"clean2\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","            4.3 Analyze & Delete Unnecessary Columns in previousDF\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Getting the 11 columns which has more than 40% unknown\n","Unwanted_previous = nullcol_40_previous[\"Column Name\"].tolist()\n","Unwanted_previous"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Listing down columns which are not needed\n","Unnecessary_previous = ['WEEKDAY_APPR_PROCESS_START','HOUR_APPR_PROCESS_START',\n","                        'FLAG_LAST_APPL_PER_CONTRACT','NFLAG_LAST_APPL_IN_DAY']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Unwanted_previous = Unwanted_previous + Unnecessary_previous\n","len(Unwanted_previous)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>\n","        Total 15 columns can be deleted from previousDF\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Dropping the unnecessary columns from previous\n","previousDF.drop(labels=Unwanted_previous,axis=1,inplace=True)\n","# Inspecting the dataframe after removal of unnecessary columns\n","previousDF.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# inspecting the column types after after removal of unnecessary columns\n","previousDF.info()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br> \n","        After deleting unnecessary columns, there are 22 columns remaining in applicationDF\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"stdval\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","             4.4 Standardize Values\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","    <span style='font-family:Georgia'>\n","        <b>Strategy for applicationDF: </b> \n","        <ul>\n","            <li>Convert DAYS_DECISION,DAYS_EMPLOYED, DAYS_REGISTRATION,DAYS_ID_PUBLISH from negative to positive as days cannot be negative.</li>\n","            <li>Convert DAYS_BIRTH from negative to positive values and calculate age and create categorical bins columns</li>\n","            <li>Categorize the amount variables into bins</li>\n","            <li>Convert region rating column and few other columns to categorical</li>\n","        </ul>       \n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Converting Negative days to positive days\n","\n","date_col = ['DAYS_BIRTH','DAYS_EMPLOYED','DAYS_REGISTRATION','DAYS_ID_PUBLISH']\n","\n","for col in date_col:\n","    applicationDF[col] = abs(applicationDF[col])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Binning Numerical Columns to create a categorical column\n","\n","# Creating bins for income amount\n","applicationDF['AMT_INCOME_TOTAL']=applicationDF['AMT_INCOME_TOTAL']/100000\n","\n","bins = [0,1,2,3,4,5,6,7,8,9,10,11]\n","slot = ['0-100K','100K-200K', '200k-300k','300k-400k','400k-500k','500k-600k','600k-700k','700k-800k','800k-900k','900k-1M', '1M Above']\n","\n","applicationDF['AMT_INCOME_RANGE']=pd.cut(applicationDF['AMT_INCOME_TOTAL'],bins,labels=slot)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["applicationDF['AMT_INCOME_RANGE'].value_counts(normalize=True)*100"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>More than 50% loan applicants  have income amount in the range of 100K-200K. Almost 92% loan applicants have income less than 300K\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Creating bins for Credit amount\n","applicationDF['AMT_CREDIT']=applicationDF['AMT_CREDIT']/100000\n","\n","bins = [0,1,2,3,4,5,6,7,8,9,10,100]\n","slots = ['0-100K','100K-200K', '200k-300k','300k-400k','400k-500k','500k-600k','600k-700k','700k-800k',\n","       '800k-900k','900k-1M', '1M Above']\n","\n","applicationDF['AMT_CREDIT_RANGE']=pd.cut(applicationDF['AMT_CREDIT'],bins=bins,labels=slots)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#checking the binning of data and % of data in each category\n","applicationDF['AMT_CREDIT_RANGE'].value_counts(normalize=True)*100"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>More Than 16% loan applicants have taken loan which amounts to more than 1M.\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Creating bins for Age\n","applicationDF['AGE'] = applicationDF['DAYS_BIRTH'] // 365\n","bins = [0,20,30,40,50,100]\n","slots = ['0-20','20-30','30-40','40-50','50 above']\n","\n","applicationDF['AGE_GROUP']=pd.cut(applicationDF['AGE'],bins=bins,labels=slots)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#checking the binning of data and % of data in each category\n","applicationDF['AGE_GROUP'].value_counts(normalize=True)*100"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>31% loan applicants have age above 50 years. More than 55% of loan applicants have age over 40 years.\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Creating bins for Employement Time\n","applicationDF['YEARS_EMPLOYED'] = applicationDF['DAYS_EMPLOYED'] // 365\n","bins = [0,5,10,20,30,40,50,60,150]\n","slots = ['0-5','5-10','10-20','20-30','30-40','40-50','50-60','60 above']\n","\n","applicationDF['EMPLOYMENT_YEAR']=pd.cut(applicationDF['YEARS_EMPLOYED'],bins=bins,labels=slots)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#checking the binning of data and % of data in each category\n","applicationDF['EMPLOYMENT_YEAR'].value_counts(normalize=True)*100"]},{"cell_type":"markdown","metadata":{},"source":["**<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>More than 55% of the loan applicants have work experience within 0-5 years and almost 80% of them have less than 10 years of work experience\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Checking the number of unique values each column possess to identify categorical columns\n","applicationDF.nunique().sort_values()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"dconv\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","             4.5 Data Type Conversion\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# inspecting the column types if they are in correct data type using the above result.\n","applicationDF.info()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>Numeric columns are already in int64 and float64 format. Hence proceeding with other columns.\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Conversion of Object and Numerical columns to Categorical Columns\n","categorical_columns = ['NAME_CONTRACT_TYPE','CODE_GENDER','NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE',\n","                       'NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','OCCUPATION_TYPE','WEEKDAY_APPR_PROCESS_START',\n","                       'ORGANIZATION_TYPE','FLAG_OWN_CAR','FLAG_OWN_REALTY','LIVE_CITY_NOT_WORK_CITY',\n","                       'REG_CITY_NOT_LIVE_CITY','REG_CITY_NOT_WORK_CITY','REG_REGION_NOT_WORK_REGION',\n","                       'LIVE_REGION_NOT_WORK_REGION','REGION_RATING_CLIENT','WEEKDAY_APPR_PROCESS_START',\n","                       'REGION_RATING_CLIENT_W_CITY'\n","                      ]\n","for col in categorical_columns:\n","    applicationDF[col] =pd.Categorical(applicationDF[col])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# inspecting the column types if the above conversion is reflected\n","applicationDF.info()"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             4.4.2 Standardize Values for previousDF\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","    <span style='font-family:Georgia'>\n","        <b>Strategy for previousDF: </b> \n","        <ul>\n","            <li>Convert DAYS_DECISION from negative to positive values and create categorical bins columns.</li>\n","            <li>Convert loan purpose and few other columns to categorical.</li>\n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Checking the number of unique values each column possess to identify categorical columns\n","previousDF.nunique().sort_values() "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# inspecting the column types if the above conversion is reflected\n","previousDF.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Converting negative days to positive days \n","previousDF['DAYS_DECISION'] = abs(previousDF['DAYS_DECISION'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#age group calculation e.g. 388 will be grouped as 300-400\n","previousDF['DAYS_DECISION_GROUP'] = (previousDF['DAYS_DECISION']-(previousDF['DAYS_DECISION'] % 400)).astype(str)+'-'+ ((previousDF['DAYS_DECISION'] - (previousDF['DAYS_DECISION'] % 400)) + (previousDF['DAYS_DECISION'] % 400) + (400 - (previousDF['DAYS_DECISION'] % 400))).astype(str)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF['DAYS_DECISION_GROUP'].value_counts(normalize=True)*100"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>Almost 37% loan applicatants have applied for a new loan within 0-400 days of previous loan decision\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Converting Categorical columns from Object to categorical \n","Catgorical_col_p = ['NAME_CASH_LOAN_PURPOSE','NAME_CONTRACT_STATUS','NAME_PAYMENT_TYPE',\n","                    'CODE_REJECT_REASON','NAME_CLIENT_TYPE','NAME_GOODS_CATEGORY','NAME_PORTFOLIO',\n","                   'NAME_PRODUCT_TYPE','CHANNEL_TYPE','NAME_SELLER_INDUSTRY','NAME_YIELD_GROUP','PRODUCT_COMBINATION',\n","                    'NAME_CONTRACT_TYPE','DAYS_DECISION_GROUP']\n","\n","for col in Catgorical_col_p:\n","    previousDF[col] =pd.Categorical(previousDF[col])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# inspecting the column types after conversion\n","previousDF.info()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"impute\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","             4.6 Null Value Data Imputation\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             4.6.1 Imputing Null Values in applicationDF\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","    <span style='font-family:Georgia'>\n","        <b>Strategy for applicationDF: </b> \n","        <ul>\n","            <li>To impute null values in categorical variables which has lower null percentage, mode() is used to impute the most frequent items.</li>\n","            <li>To impute null values in categorical variables which has higher null percentage, a new category is created.</li>\n","            <li>To impute null values in numerical variables which has lower null percentage, median() is used as </li>\n","            <ul>\n","                <li>There are no outliers in the columns</li>\n","                <li>Mean returned decimal values and median returned whole numbers and the columns were number of requests</li>\n","            </ul>        \n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# checking the null value % of each column in applicationDF dataframe\n","round(applicationDF.isnull().sum() / applicationDF.shape[0] * 100.00,2)\n"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Impute categorical variable 'NAME_TYPE_SUITE' which has lower null percentage(0.42%) with the most frequent category using mode()[0]:\n","    </span>\n","</p>\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["applicationDF['NAME_TYPE_SUITE'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["applicationDF['NAME_TYPE_SUITE'].fillna((applicationDF['NAME_TYPE_SUITE'].mode()[0]),inplace = True)"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Impute categorical variable 'OCCUPATION_TYPE' which has higher null percentage(31.35%) with a new category as assigning to any existing category might influence the analysis:\n","    </span>\n","</p>\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","applicationDF['OCCUPATION_TYPE'] = applicationDF['OCCUPATION_TYPE'].cat.add_categories('Unknown')\n","applicationDF['OCCUPATION_TYPE'].fillna('Unknown', inplace =True) "]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Impute numerical variables with the median as there are no outliers that can be seen from results of describe() and mean() returns decimal values and these columns represent number of enquiries made which cannot be decimal:\n","    </span>\n","</p>\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["applicationDF[['AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_DAY',\n","               'AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON',\n","               'AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']].describe()"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Impute with median as mean has decimals and this is number of requests\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["amount = ['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_MON',\n","         'AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']\n","\n","for col in amount:\n","    applicationDF[col].fillna(applicationDF[col].median(),inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# checking the null value % of each column in previousDF dataframe\n","round(applicationDF.isnull().sum() / previousDF.shape[0] * 100.00,2)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br> We still have few null values in the columns: AMT_GOODS_PRICE, OBS_30_CNT_SOCIAL_CIRCLE, DEF_30_CNT_SOCIAL_CIRCLE, OBS_60_CNT_SOCIAL_CIRCLE, DEF_60_CNT_SOCIAL_CIRCLE. We can ignore as this percentage is very less.\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["> <h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             4.6.2 Imputing Null Values in previousDF\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","    <span style='font-family:Georgia'>\n","        <b>Strategy for applicationDF: </b> \n","        <ul>\n","            <li>To impute null values in numerical column, we analysed the loan status and assigned values.</li>\n","            <li>To impute null values in continuous variables, we plotted the distribution of the columns and used </li>\n","            <ul>\n","                <li>median if the distribution is skewed</li>\n","                <li>mode if the distribution pattern is preserved.</li>\n","            </ul>        \n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# checking the null value % of each column in previousDF dataframe\n","round(previousDF.isnull().sum() / previousDF.shape[0] * 100.00,2)"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Impute AMT_ANNUITY with median as the distribution is greatly skewed:\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(6,6))\n","sns.kdeplot(previousDF['AMT_ANNUITY'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>There is a single peak at the left side of the distribution and it indicates the presence of outliers and hence imputing with mean would not be the right approach and hence imputing with median.\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF['AMT_ANNUITY'].fillna(previousDF['AMT_ANNUITY'].median(),inplace = True)"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Impute AMT_GOODS_PRICE with mode as the distribution is closely similar:\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(6,6))\n","sns.kdeplot(previousDF['AMT_GOODS_PRICE'][pd.notnull(previousDF['AMT_GOODS_PRICE'])])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           There are several peaks along the distribution. Let's impute using the mode, mean and median and see if the distribution is still about the same.\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["statsDF = pd.DataFrame() # new dataframe with columns imputed with mode, median and mean\n","statsDF['AMT_GOODS_PRICE_mode'] = previousDF['AMT_GOODS_PRICE'].fillna(previousDF['AMT_GOODS_PRICE'].mode()[0])\n","statsDF['AMT_GOODS_PRICE_median'] = previousDF['AMT_GOODS_PRICE'].fillna(previousDF['AMT_GOODS_PRICE'].median())\n","statsDF['AMT_GOODS_PRICE_mean'] = previousDF['AMT_GOODS_PRICE'].fillna(previousDF['AMT_GOODS_PRICE'].mean())\n","\n","cols = ['AMT_GOODS_PRICE_mode', 'AMT_GOODS_PRICE_median','AMT_GOODS_PRICE_mean']\n","\n","plt.figure(figsize=(18,10))\n","plt.suptitle('Distribution of Original data vs imputed data')\n","plt.subplot(221)\n","sns.distplot(previousDF['AMT_GOODS_PRICE'][pd.notnull(previousDF['AMT_GOODS_PRICE'])]);\n","for i in enumerate(cols): \n","    plt.subplot(2,2,i[0]+2)\n","    sns.distplot(statsDF[i[1]])"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>The original distribution is closer with the distribution of data imputed with mode in this case\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF['AMT_GOODS_PRICE'].fillna(previousDF['AMT_GOODS_PRICE'].mode()[0], inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Impute CNT_PAYMENT with 0 as the NAME_CONTRACT_STATUS for these indicate that most of these loans were not started:\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF.loc[previousDF['CNT_PAYMENT'].isnull(),'NAME_CONTRACT_STATUS'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF['CNT_PAYMENT'].fillna(0,inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# checking the null value % of each column in previousDF dataframe\n","round(previousDF.isnull().sum() / previousDF.shape[0] * 100.00,2)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> <br>We still have few null values in the PRODUCT_COMBINATION column. We can ignore as this percentage is very less.\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"outlier\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","             4.7 Identifying the outliers\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Finding outlier information in applicationDF\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(22,10))\n","\n","app_outlier_col_1 = ['AMT_ANNUITY','AMT_INCOME_TOTAL','AMT_CREDIT','AMT_GOODS_PRICE','DAYS_EMPLOYED']\n","app_outlier_col_2 = ['CNT_CHILDREN','DAYS_BIRTH']\n","for i in enumerate(app_outlier_col_1):\n","    plt.subplot(2,4,i[0]+1)\n","    sns.boxplot(y=applicationDF[i[1]])\n","    plt.title(i[1])\n","    plt.ylabel(\"\")\n","\n","for i in enumerate(app_outlier_col_2):\n","    plt.subplot(2,4,i[0]+6)\n","    sns.boxplot(y=applicationDF[i[1]])\n","    plt.title(i[1])\n","    plt.ylabel(\"\")"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b><br>It can be seen that in current application data\n","        <ol>\n","            <li>AMT_ANNUITY, AMT_CREDIT, AMT_GOODS_PRICE,CNT_CHILDREN have some number of outliers.</li>\n","            <li>AMT_INCOME_TOTAL has huge number of outliers which indicate that few of the loan applicants have high income when compared to the others.</li>\n","            <li>DAYS_BIRTH has no outliers which means the data available is reliable.</li>\n","            <li>DAYS_EMPLOYED has outlier values around 350000(days) which is around 958 years which is impossible and hence this has to be incorrect entry.</li>\n","        </ol>        \n","    </span>    \n","</div>\n","<p>\n","    <span style='font-family:Georgia'>\n","           We can see the stats for these columns below as well.\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["applicationDF[['AMT_ANNUITY', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_GOODS_PRICE', 'DAYS_BIRTH','CNT_CHILDREN','DAYS_EMPLOYED']].describe()"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Finding outlier information in previousDF\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(22,8))\n","\n","prev_outlier_col_1 = ['AMT_ANNUITY','AMT_APPLICATION','AMT_CREDIT','AMT_GOODS_PRICE','SELLERPLACE_AREA']\n","prev_outlier_col_2 = ['SK_ID_CURR','DAYS_DECISION','CNT_PAYMENT']\n","for i in enumerate(prev_outlier_col_1):\n","    plt.subplot(2,4,i[0]+1)\n","    sns.boxplot(y=previousDF[i[1]])\n","    plt.title(i[1])\n","    plt.ylabel(\"\")\n","\n","for i in enumerate(prev_outlier_col_2):\n","    plt.subplot(2,4,i[0]+6)\n","    sns.boxplot(y=previousDF[i[1]])\n","    plt.title(i[1])\n","    plt.ylabel(\"\") "]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Insight: </b> It can be seen that in previous application data\n","        <ol>\n","            <li>AMT_ANNUITY, AMT_APPLICATION, AMT_CREDIT, AMT_GOODS_PRICE, SELLERPLACE_AREA have huge number of outliers.</li>\n","            <li>CNT_PAYMENT has few outlier values.</li>\n","            <li>SK_ID_CURR is an ID column and hence no outliers.</li>\n","            <li>DAYS_DECISION has little number of outliers indicating that these previous applications decisions were taken long back.</li>\n","        </ol>        \n","    </span>    \n","</div>\n","<p>\n","    <span style='font-family:Georgia'>\n","           We can see the stats for these columns below as well.\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["previousDF[['AMT_ANNUITY', 'AMT_APPLICATION', 'AMT_CREDIT', 'AMT_GOODS_PRICE', 'SELLERPLACE_AREA','CNT_PAYMENT','DAYS_DECISION']].describe()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"analysis\"></a>\n","<h2>   \n","      <font color = blue >\n","            <span style='font-family:Georgia'>\n","            5. Data Analysis\n","            </span>   \n","        </font>    \n","</h2>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","    <span style='font-family:Georgia'>\n","        <b>Strategy:</b> \n","        <p>The data analysis flow has been planned in following way :</p>\n","        <ul>\n","            <li>Imbalance in Data</li>\n","            <li>Categorical Data Analysis</li>\n","            <ul>\n","                <li>Categorical segmented Univariate Analysis</li>\n","                <li>Categorical Bi/Multivariate analysis</li>\n","            </ul>\n","            <li>Numeric Data Analysis</li>\n","            <ul>\n","                <li>Bi-furcation of databased based on TARGET data</li>\n","                <li>Correlation Matrix</li>\n","                <li>Numerical segmented Univariate Analysis</li>\n","                <li>Numerical Bi/Multivariate analysis</li>\n","            </ul> \n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"imbalance\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","             5.1 Imbalance Analysis\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Imbalance = applicationDF[\"TARGET\"].value_counts().reset_index()\n","\n","plt.figure(figsize=(10,4))\n","x= ['Repayer','Defaulter']\n","sns.barplot(x,\"TARGET\",data = Imbalance,palette= ['g','r'])\n","plt.xlabel(\"Loan Repayment Status\")\n","plt.ylabel(\"Count of Repayers & Defaulters\")\n","plt.title(\"Imbalance Plotting\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["count_0 = Imbalance.iloc[0][\"TARGET\"]\n","count_1 = Imbalance.iloc[1][\"TARGET\"]\n","count_0_perc = round(count_0/(count_0+count_1)*100,2)\n","count_1_perc = round(count_1/(count_0+count_1)*100,2)\n","\n","print('Ratios of imbalance in percentage with respect to Repayer and Defaulter datas are: %.2f and %.2f'%(count_0_perc,count_1_perc))\n","print('Ratios of imbalance in relative with respect to Repayer and Defaulter datas is %.2f : 1 (approx)'%(count_0/count_1))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"oltfunc\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","             5.2 Plotting Functions\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","           Following are the common functions customized to perform uniform anaysis that is called for all plots:\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# function for plotting repetitive countplots in univariate categorical analysis on applicationDF\n","# This function will create two subplots: \n","# 1. Count plot of categorical column w.r.t TARGET; \n","# 2. Percentage of defaulters within column\n","\n","def univariate_categorical(feature,ylog=False,label_rotation=False,horizontal_layout=True):\n","    temp = applicationDF[feature].value_counts()\n","    df1 = pd.DataFrame({feature: temp.index,'Number of contracts': temp.values})\n","\n","    # Calculate the percentage of target=1 per category value\n","    cat_perc = applicationDF[[feature, 'TARGET']].groupby([feature],as_index=False).mean()\n","    cat_perc[\"TARGET\"] = cat_perc[\"TARGET\"]*100\n","    cat_perc.sort_values(by='TARGET', ascending=False, inplace=True)\n","    \n","    if(horizontal_layout):\n","        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n","    else:\n","        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(20,24))\n","        \n","    # 1. Subplot 1: Count plot of categorical column\n","    # sns.set_palette(\"Set2\")\n","    s = sns.countplot(ax=ax1, \n","                    x = feature, \n","                    data=applicationDF,\n","                    hue =\"TARGET\",\n","                    order=cat_perc[feature],\n","                    palette=['g','r'])\n","    \n","    # Define common styling\n","    ax1.set_title(feature, fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Blue'}) \n","    ax1.legend(['Repayer','Defaulter'])\n","    \n","    # If the plot is not readable, use the log scale.\n","    if ylog:\n","        ax1.set_yscale('log')\n","        ax1.set_ylabel(\"Count (log)\",fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Blue'})   \n","    \n","    \n","    if(label_rotation):\n","        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n","    \n","    # 2. Subplot 2: Percentage of defaulters within the categorical column\n","    s = sns.barplot(ax=ax2, \n","                    x = feature, \n","                    y='TARGET', \n","                    order=cat_perc[feature], \n","                    data=cat_perc,\n","                    palette='Set2')\n","    \n","    if(label_rotation):\n","        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n","    plt.ylabel('Percent of Defaulters [%]', fontsize=10)\n","    plt.tick_params(axis='both', which='major', labelsize=10)\n","    ax2.set_title(feature + \" Defaulter %\", fontdict={'fontsize' : 15, 'fontweight' : 5, 'color' : 'Blue'}) \n","\n","    plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# function for plotting repetitive countplots in bivariate categorical analysis\n","\n","def bivariate_bar(x,y,df,hue,figsize):\n","    \n","    plt.figure(figsize=figsize)\n","    sns.barplot(x=x,\n","                  y=y,\n","                  data=df, \n","                  hue=hue, \n","                  palette =['g','r'])     \n","        \n","    # Defining aesthetics of Labels and Title of the plot using style dictionaries\n","    plt.xlabel(x,fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Blue'})    \n","    plt.ylabel(y,fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Blue'})    \n","    plt.title(col, fontdict={'fontsize' : 15, 'fontweight' : 5, 'color' : 'Blue'}) \n","    plt.xticks(rotation=90, ha='right')\n","    plt.legend(labels = ['Repayer','Defaulter'])\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# function for plotting repetitive rel plots in bivaritae numerical analysis on applicationDF\n","\n","def bivariate_rel(x,y,data, hue, kind, palette, legend,figsize):\n","    \n","    plt.figure(figsize=figsize)\n","    sns.relplot(x=x, \n","                y=y, \n","                data=applicationDF, \n","                hue=\"TARGET\",\n","                kind=kind,\n","                palette = ['g','r'],\n","                legend = False)\n","    plt.legend(['Repayer','Defaulter'])\n","    plt.xticks(rotation=90, ha='right')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#function for plotting repetitive countplots in univariate categorical analysis on the merged df\n","\n","def univariate_merged(col,df,hue,palette,ylog,figsize):\n","    plt.figure(figsize=figsize)\n","    ax=sns.countplot(x=col, \n","                  data=df,\n","                  hue= hue,\n","                  palette= palette,\n","                  order=df[col].value_counts().index)\n","    \n","\n","    if ylog:\n","        plt.yscale('log')\n","        plt.ylabel(\"Count (log)\",fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Blue'})     \n","    else:\n","        plt.ylabel(\"Count\",fontdict={'fontsize' : 10, 'fontweight' : 3, 'color' : 'Blue'})       \n","\n","    plt.title(col , fontdict={'fontsize' : 15, 'fontweight' : 5, 'color' : 'Blue'}) \n","    plt.legend(loc = \"upper right\")\n","    plt.xticks(rotation=90, ha='right')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Function to plot point plots on merged dataframe\n","\n","def merged_pointplot(x,y):\n","    plt.figure(figsize=(8,4))\n","    sns.pointplot(x=x, \n","                  y=y, \n","                  hue=\"TARGET\", \n","                  data=loan_process_df,\n","                  palette =['g','r'])\n","   # plt.legend(['Repayer','Defaulter'])"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"catvar\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","             5.3 Categorical Variables Analysis\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             5.3.1 Segmented Univariate Analysis\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking the contract type based on loan repayment status\n","univariate_categorical('NAME_CONTRACT_TYPE',True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> <br>Contract type: Revolving loans are just a small fraction (10%) from the total number of loans; in the same time, a larger amount of Revolving loans, comparing with their frequency, are not repaid. \n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking the type of Gender on loan repayment status\n","univariate_categorical('CODE_GENDER')"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> <br>The number of female clients is almost double the number of male clients. Based on the percentage of defaulted credits, males have a higher chance of not returning their loans (~10%), comparing with women (~7%)  \n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking if owning a car is related to loan repayment status\n","univariate_categorical('FLAG_OWN_CAR')"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <br>Clients who own a car are half in number of the clients who dont own a car. But based on the percentage of deault, there is no correlation between owning a car and loan repayment as in both cases the default percentage is almost same.      \n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking if owning a realty is related to loan repayment status\n","univariate_categorical('FLAG_OWN_REALTY')"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <br>The clients who own real estate are more than double of the ones that don't own. But the defaulting rate of both categories are around the same (~8%). Thus there is no correlation between owning a reality and defaulting the loan.      \n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Housing Type based on loan repayment status\n","univariate_categorical(\"NAME_HOUSING_TYPE\",True,True,True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>Majority of people live in House/apartment</li>\n","            <li>People living in office apartments have lowest default rate</li>\n","            <li>People living with parents (~11.5%) and living in rented apartments(>12%) have higher probability of defaulting </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Family status based on loan repayment status\n","univariate_categorical(\"NAME_FAMILY_STATUS\",False,True,True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>Most of the people who have taken loan are married, followed by Single/not married and civil marriage </li>\n","            <li>In terms of percentage of not repayment of loan, Civil marriage has the highest percent of not repayment (10%), with Widow the lowest (exception being Unknown). </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Education Type based on loan repayment status\n","univariate_categorical(\"NAME_EDUCATION_TYPE\",True,True,True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>Majority of the clients have Secondary / secondary special education, followed by clients with Higher education. Only a very small number having an academic degree</li>\n","            <li>The Lower secondary category, although rare, have the largest rate of not returning the loan (11%). The people with Academic degree have less than 2% defaulting rate. </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Income Type based on loan repayment status\n","univariate_categorical(\"NAME_INCOME_TYPE\",True,True,False)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ul>\n","            <li>Most of applicants for loans have income type as Working, followed by Commercial associate, Pensioner and State servant.</li>\n","            <li>The applicants with the type of income Maternity leave have almost 40% ratio of not returning loans, followed by Unemployed (37%). The rest of types of incomes are under the average of 10% for not returning loans.</li>\n","            <li>Student and Businessmen, though less in numbers do not have any default record. Thus these two category are <b>safest</b> for providing loan.</li>  \n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Region rating where applicant lives based on loan repayment status\n","univariate_categorical(\"REGION_RATING_CLIENT\",False,False,True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>Most of the applicants are living in Region_Rating 2 place.</li>\n","            <li>Region Rating 3 has the highest default rate (11%)</li>\n","            <li>Applicant living in Region_Rating 1 has the lowest probability of defaulting, thus <b>safer</b> for approving loans </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Occupation Type where applicant lives based on loan repayment status\n","univariate_categorical(\"OCCUPATION_TYPE\",False,True,False)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>Most of the loans are taken by Laborers, followed by Sales staff. IT staff take the lowest amount of loans.</li>\n","            <li>The category with highest percent of not repaid loans are Low-skill Laborers (above 17%), followed by Drivers and Waiters/barmen staff, Security staff, Laborers and Cooking staff. </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking Loan repayment status based on Organization type\n","univariate_categorical(\"ORGANIZATION_TYPE\",True,True,False)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>Organizations with highest percent of loans not repaid are Transport: type 3 (16%), Industry: type 13 (13.5%), Industry: type 8 (12.5%) and Restaurant (less than 12%). Self employed people have relative high defaulting rate, and thus should be avoided to be approved for loan or provide loan with higher interest rate to mitigate the risk of defaulting.</li>\n","            <li>Most of the people application for loan are from Business Entity Type 3 </li>\n","            <li>For a very high number of applications, Organization type information is unavailable(XNA)</li>\n","        </ol>\n","        It can be seen that following category of organization type has lesser defaulters thus safer for providing loans:\n","        <ul>\n","            <li>Trade Type 4 and 5</li>\n","            <li>Industry type 8</li>\n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Flag_Doc_3 submission status based on loan repayment status\n","univariate_categorical(\"FLAG_DOCUMENT_3\",False,False,True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <br>There is no significant correlation between repayers and defaulters in terms of submitting document 3 as we see even if applicants have submitted the document, they have defaulted a slightly more (~9%) than who have not submitted the document (6%)\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Age Group based on loan repayment status\n","univariate_categorical(\"AGE_GROUP\",False,False,True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>People in the age group range 20-40 have higher probability of defaulting</li>\n","            <li>People above age of 50 have low probability of defailting </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Employment_Year based on loan repayment status\n","univariate_categorical(\"EMPLOYMENT_YEAR\",False,False,True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>Majority of the applicants have been employeed in between 0-5 years. The defaulting rating of this group is also the highest which is 10%</li>\n","            <li>With increase of employment year, defaulting rate is gradually decreasing with people having 40+ year experience having less than 1% default rate </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Amount_Credit based on loan repayment status\n","univariate_categorical(\"AMT_CREDIT_RANGE\",False,False,False)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>More than 80% of the loan provided are for amount less than 900,000</li>\n","            <li>People who get loan for 300-600k tend to default more than others. </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Amount_Income Range based on loan repayment status\n","univariate_categorical(\"AMT_INCOME_RANGE\",False,False,False)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>90% of the applications have Income total less than 300,000</li>\n","            <li>Application with Income less than 300,000 has high probability of defaulting</li>\n","            <li>Applicant with Income more than 700,000 are less likely to default </li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Number of children based on loan repayment status\n","univariate_categorical(\"CNT_CHILDREN\",True)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ol>\n","            <li>Most of the applicants do not have children</li>\n","            <li>Very few clients have more than 3 children.</li>\n","            <li>Client who have more than 4 children has a very high default rate with child count 9 and 11 showing 100% default rate</li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Analyzing Number of family members based on loan repayment status\n","univariate_categorical(\"CNT_FAM_MEMBERS\",True, False, False)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <br>Family member follows the same trend as children where having more family members increases the risk of defaulting\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             5.3.2 Categorical Bi/Multivariate Analysis\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["applicationDF.groupby('NAME_INCOME_TYPE')['AMT_INCOME_TOTAL'].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Income type vs Income Amount Range\n","bivariate_bar(\"NAME_INCOME_TYPE\",\"AMT_INCOME_TOTAL\",applicationDF,\"TARGET\",(18,10))"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <br>It can be seen that business man's income is the highest and the estimated range with default 95% confidence level seem to indicate that the income of a business man could be in the range of slightly close to 4 lakhs and slightly above 10 lakhs\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"numvar\"></a>\n","<h3>   \n","      <font color = purple >\n","            <span style='font-family:Georgia'>\n","             5.4 Numeric Variables Analysis\n","            </span>   \n","        </font>    \n","</h3>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             5.4.1 Bifurcating the applicationDF dataframe based on Target value 0 and 1 for correlation and other analysis\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["applicationDF.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Bifurcating the applicationDF dataframe based on Target value 0 and 1 for correlation and other analysis\n","cols_for_correlation = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', \n","                        'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', \n","                        'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n","                        'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', \n","                        'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT',\n","                        'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START',\n","                        'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', \n","                        'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE',\n","                        'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_3', \n","                        'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n","                        'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n","\n","\n","Repayer_df = applicationDF.loc[applicationDF['TARGET']==0, cols_for_correlation] # Repayers\n","Defaulter_df = applicationDF.loc[applicationDF['TARGET']==1, cols_for_correlation] # Defaulters"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             5.4.2 Correlation between numeric variable\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Getting the top 10 correlation for the Repayers data\n","corr_repayer = Repayer_df.corr()\n","corr_repayer = corr_repayer.where(np.triu(np.ones(corr_repayer.shape),k=1).astype(np.bool))\n","corr_df_repayer = corr_repayer.unstack().reset_index()\n","corr_df_repayer.columns =['VAR1','VAR2','Correlation']\n","corr_df_repayer.dropna(subset = [\"Correlation\"], inplace = True)\n","corr_df_repayer[\"Correlation\"]=corr_df_repayer[\"Correlation\"].abs() \n","corr_df_repayer.sort_values(by='Correlation', ascending=False, inplace=True) \n","corr_df_repayer.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = plt.figure(figsize=(12,12))\n","ax = sns.heatmap(Repayer_df.corr(), cmap=\"RdYlGn\",annot=False,linewidth =1)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <br>Correlating factors amongst repayers:<br>\n","            Credit amount is highly correlated with\n","            <ul>                \n","                <li> amount of goods price</li>\n","                <li> loan annuity</li>\n","                <li> total income</li>\n","        </ul>\n","        We can also see that repayers have high correlation in number of days employed.\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Getting the top 10 correlation for the Defaulter data\n","corr_Defaulter = Defaulter_df.corr()\n","corr_Defaulter = corr_Defaulter.where(np.triu(np.ones(corr_Defaulter.shape),k=1).astype(np.bool))\n","corr_df_Defaulter = corr_Defaulter.unstack().reset_index()\n","corr_df_Defaulter.columns =['VAR1','VAR2','Correlation']\n","corr_df_Defaulter.dropna(subset = [\"Correlation\"], inplace = True)\n","corr_df_Defaulter[\"Correlation\"]=corr_df_Defaulter[\"Correlation\"].abs()\n","corr_df_Defaulter.sort_values(by='Correlation', ascending=False, inplace=True)\n","corr_df_Defaulter.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = plt.figure(figsize=(12,12))\n","ax = sns.heatmap(Defaulter_df.corr(), cmap=\"RdYlGn\",annot=False,linewidth =1)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ul>\n","            <li> Credit amount is highly correlated with amount of goods price which is same as repayers. </li>\n","            <li> But the loan annuity correlation with credit amount has slightly reduced in defaulters(0.75) when compared to repayers(0.77)</li>\n","            <li> We can also see that repayers have high correlation in number of days employed(0.62) when compared to defaulters(0.58).</li>\n","            <li> There is a severe drop in the correlation between total income of the client and the credit amount(0.038) amongst defaulters whereas it is 0.342 among repayers.</li>\n","            <li> Days_birth and number of children correlation has reduced to 0.259 in defaulters when compared to 0.337 in repayers.</li>\n","            <li> There is a slight increase in defaulted to observed count in social circle among defaulters(0.264) when compared to repayers(0.254)</li>\n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             5.4.3 Numerical Univariate Analysis\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plotting the numerical columns related to amount as distribution plot to see density\n","amount = applicationDF[[ 'AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY', 'AMT_GOODS_PRICE']]\n","\n","fig = plt.figure(figsize=(16,12))\n","\n","for i in enumerate(amount):\n","    plt.subplot(2,2,i[0]+1)\n","    sns.distplot(Defaulter_df[i[1]], hist=False, color='r',label =\"Defaulter\")\n","    sns.distplot(Repayer_df[i[1]], hist=False, color='g', label =\"Repayer\")\n","    plt.title(i[1], fontdict={'fontsize' : 15, 'fontweight' : 5, 'color' : 'Blue'}) \n","    \n","plt.legend()\n","\n","plt.show() "]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ul>\n","            <li> Most no of loans are given for goods price below 10 lakhs </li>\n","            <li> Most people pay annuity below 50000 for the credit loan</li>\n","            <li> Credit amount of the loan is mostly less then 10 lakhs</li>\n","            <li> The repayers and defaulters distribution overlap in all the plots and hence we cannot use any of these variables in isolation to make a decision</li>\n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<h4>   \n","      <font color = darkgreen >\n","            <span style='font-family:Georgia'>\n","             5.4.4 Numerical Bivariate Analysis\n","            </span>   \n","        </font>    \n","</h4>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking the relationship between Goods price and credit and comparing with loan repayment staus\n","bivariate_rel('AMT_GOODS_PRICE','AMT_CREDIT',applicationDF,\"TARGET\", \"line\", ['g','r'], False,(15,6))"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <br>When the credit amount goes beyond 3M, there is an increase in defaulters.\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plotting pairplot between amount variable to draw reference against loan repayment status\n","amount = applicationDF[[ 'AMT_INCOME_TOTAL','AMT_CREDIT',\n","                         'AMT_ANNUITY', 'AMT_GOODS_PRICE','TARGET']]\n","amount = amount[(amount[\"AMT_GOODS_PRICE\"].notnull()) & (amount[\"AMT_ANNUITY\"].notnull())]\n","ax= sns.pairplot(amount,hue=\"TARGET\",palette=[\"g\",\"r\"])\n","ax.fig.legend(labels=['Repayer','Defaulter'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ul>\n","            <li> When amt_annuity >15000 amt_goods_price> 3M, there is a lesser chance of defaulters  </li>\n","            <li> AMT_CREDIT and AMT_GOODS_PRICE are highly correlated as based on the scatterplot where most of the data are consolidated in form of a line</li>\n","            <li> There are very less defaulters for AMT_CREDIT >3M</li>\n","            <li> Inferences related to distribution plot has been already mentioned in previous distplot graphs inferences section</li>\n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"merge\"></a>\n","<h2>   \n","      <font color = blue >\n","            <span style='font-family:Georgia'>\n","            6. Merged Dataframes Analysis\n","            </span>   \n","        </font>    \n","</h2>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#merge both the dataframe on SK_ID_CURR with Inner Joins\n","loan_process_df = pd.merge(applicationDF, previousDF, how='inner', on='SK_ID_CURR')\n","loan_process_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Checking the details of the merged dataframe\n","loan_process_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking the element count of the dataframe\n","loan_process_df.size"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# checking the columns and column types of the dataframe\n","loan_process_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking merged dataframe numerical columns statistics\n","loan_process_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Bifurcating the applicationDF dataframe based on Target value 0 and 1 for correlation and other analysis\n","\n","L0 = loan_process_df[loan_process_df['TARGET']==0] # Repayers\n","L1 = loan_process_df[loan_process_df['TARGET']==1] # Defaulters"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","        <b> Plotting Contract Status vs purpose of the loan: </b>\n","    </span>\n","</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["univariate_merged(\"NAME_CASH_LOAN_PURPOSE\",L0,\"NAME_CONTRACT_STATUS\",[\"#548235\",\"#FF0000\",\"#0070C0\",\"#FFFF00\"],True,(18,7))\n","\n","univariate_merged(\"NAME_CASH_LOAN_PURPOSE\",L1,\"NAME_CONTRACT_STATUS\",[\"#548235\",\"#FF0000\",\"#0070C0\",\"#FFFF00\"],True,(18,7))"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ul>\n","            <li> Loan purpose has high number of unknown values (XAP, XNA)</li>\n","            <li> Loan taken for the purpose of Repairs seems to have highest default rate</li>\n","            <li> A very high number application have been rejected by bank or refused by client which has purpose as repair or other. This shows that purpose repair is taken as high risk by bank and either they are rejected or bank offers very high loan interest rate which is not feasible by the clients, thus they refuse the loan.</li>\n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Checking the Contract Status based on loan repayment status and whether there is any business loss or financial loss\n","univariate_merged(\"NAME_CONTRACT_STATUS\",loan_process_df,\"TARGET\",['g','r'],False,(12,8))\n","g = loan_process_df.groupby(\"NAME_CONTRACT_STATUS\")[\"TARGET\"]\n","df1 = pd.concat([g.value_counts(),round(g.value_counts(normalize=True).mul(100),2)],axis=1, keys=('Counts','Percentage'))\n","df1['Percentage'] = df1['Percentage'].astype(str) +\"%\" # adding percentage symbol in the results for understanding\n","print (df1)"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b> \n","        <ul>\n","            <li> 90% of the previously cancelled client have actually repayed the loan. Revisiting the interest rates would increase business opoortunity for these clients</li>\n","            <li> 88% of the clients who have been previously refused a loan has payed back the loan in current case.</li>\n","            <li> Refual reason should be recorded for further analysis as these clients would turn into potential repaying customer. </li>\n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plotting the relationship between income total and contact status\n","merged_pointplot(\"NAME_CONTRACT_STATUS\",'AMT_INCOME_TOTAL')"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b><br>\n","        The point plot show that the people who have not used offer earlier have defaulted even when there average income is higher than others\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plotting the relationship between people who defaulted in last 60 days being in client's social circle and contact status\n","merged_pointplot(\"NAME_CONTRACT_STATUS\",'DEF_60_CNT_SOCIAL_CIRCLE')"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Inferences: </b><br> \n","        Clients who have average of 0.13 or higher DEF_60_CNT_SOCIAL_CIRCLE score tend to default more and hence client's social circle has to be analysed before providing the loan.\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"conclusion\"></a>\n","<h2>   \n","      <font color = blue >\n","            <span style='font-family:Georgia'>\n","            7. Conclusions\n","            </span>   \n","        </font>    \n","</h2>"]},{"cell_type":"markdown","metadata":{},"source":["<p>\n","    <span style='font-family:Georgia'>\n","        After analysing the datasets, there are few attributes of a client with which the bank would be able to identify if they will repay the loan or not. The analysis is consised as below with the contributing factors and categorization:\n","    </span>\n","</p>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-success\">\n","    <span style='font-family:Georgia'>\n","        <b>Decisive Factor whether an applicant will be Repayer: </b> \n","        <ol>\n","            <li>NAME_EDUCATION_TYPE: Academic degree has less defaults. </li>\n","            <li>NAME_INCOME_TYPE: Student and Businessmen have no defaults.</li>\n","            <li>REGION_RATING_CLIENT: RATING 1 is safer.</li>\n","            <li>ORGANIZATION_TYPE: Clients with Trade Type 4 and 5 and Industry type 8 have defaulted less than 3%</li>\n","            <li>DAYS_BIRTH: People above age of 50 have low probability of defaulting</li>\n","            <li>DAYS_EMPLOYED: Clients with 40+ year experience having less than 1% default rate</li>\n","            <li>AMT_INCOME_TOTAL:Applicant with Income more than 700,000 are less likely to default</li>\n","            <li>NAME_CASH_LOAN_PURPOSE: Loans bought for Hobby, Buying garage are being repayed mostly.</li>\n","            <li>CNT_CHILDREN: People with zero to two children tend to repay the loans.</li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-danger\">\n","    <span style='font-family:Georgia'>\n","        <b>Decisive Factor whether an applicant will be Defaulter: </b> \n","        <ol>\n","            <li>CODE_GENDER: Men are at relatively higher default rate</li>\n","            <li>NAME_FAMILY_STATUS : People who have civil marriage or who are single default a lot. </li>\n","            <li>NAME_EDUCATION_TYPE: People with Lower Secondary & Secondary education</li>\n","            <li>NAME_INCOME_TYPE: Clients who are either at Maternity leave OR Unemployed default a lot.</li>\n","            <li>REGION_RATING_CLIENT: People who live in Rating 3 has highest defaults.</li>\n","            <li>OCCUPATION_TYPE: Avoid Low-skill Laborers, Drivers and Waiters/barmen staff, Security staff, Laborers and Cooking staff as the default rate is huge.</li>\n","            <li>ORGANIZATION_TYPE: Organizations with highest percent of loans not repaid are Transport: type 3 (16%), Industry: type 13 (13.5%), Industry: type 8 (12.5%) and Restaurant (less than 12%). Self-employed people have relative high defaulting rate, and thus should be avoided to be approved for loan or provide loan with higher interest rate to mitigate the risk of defaulting.</li>\n","            <li>DAYS_BIRTH: Avoid young people who are in age group of 20-40 as they have higher probability of defaulting</li>\n","            <li>DAYS_EMPLOYED: People who have less than 5 years of employment have high default rate.</li>\n","            <li>CNT_CHILDREN & CNT_FAM_MEMBERS: Client who have children equal to or more than 9 default 100% and hence their applications are to be rejected.</li>\n","            <li>AMT_GOODS_PRICE: When the credit amount goes beyond 3M, there is an increase in defaulters.</li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-warning\">\n","    <span style='font-family:Georgia'>\n","        <p>The following attributes indicate that people from these category tend to default but then due to the number of people and the amount of loan, the bank could provide loan with higher interest to mitigate any default risk thus preventing business loss:  </p> \n","        <ol>\n","            <li>NAME_HOUSING_TYPE: High number of loan applications are from the category of people who live in Rented apartments & living with parents and hence offering the loan would mitigate the loss if any of those default.</li>\n","            <li>AMT_CREDIT: People who get loan for 300-600k tend to default more than others and hence having higher interest specifically for this credit range would be ideal.</li>\n","            <li>AMT_INCOME: Since 90% of the applications have Income total less than 300,000 and they have high probability of defaulting, they could be offered loan with higher interest compared to other income category.</li>\n","            <li>CNT_CHILDREN & CNT_FAM_MEMBERS: Clients who have 4 to 8 children has a very high default rate and hence higher interest should be imposed on their loans.</li>\n","            <li>NAME_CASH_LOAN_PURPOSE: Loan taken for the purpose of Repairs seems to have highest default rate. A very high number applications have been rejected by bank or refused by client in previous applications as well which has purpose as repair or other. This shows that purpose repair is taken as high risk by bank and either they are rejected, or bank offers very high loan interest rate which is not feasible by the clients, thus they refuse the loan. The same approach could be followed in future as well.</li>\n","        </ol>\n","    </span>    \n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"alert alert-block alert-info\">\n","    <span style='font-family:Georgia'>\n","        <b>Other suggestions: </b>\n","        <ul>\n","            <li>90% of the previously cancelled client have actually repayed the loan. Record the reason for cancellation which might help the bank to determine and negotiate terms with these repaying customers in future for increase business opportunity. </li>\n","            <li>88% of the clients who were refused by bank for loan earlier have now turned into a repaying client. Hence documenting the reason for rejection could mitigate the business loss and these clients could be contacted for further loans.</li>\n","        </ul>\n","    </span>    \n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":807638,"sourceId":1383922,"sourceType":"datasetVersion"}],"dockerImageVersionId":29985,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
